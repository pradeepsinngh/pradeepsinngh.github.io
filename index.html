<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    project {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="seal_icon.png">
  <title>Pradeep Singh</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Pradeep Singh</name>
        </p>
        <p>I am a graduate student at <a href="https://www.sdsu.edu/">San Diego State University</a>, in the <a href="http://www.csrc.sdsu.edu//">Computatioanl Science Research Center</a> where I work on Computational neuroscience with <a href="https://www.researchgate.net/profile/Patrick_Shoemaker">Prof. Patrick Shoemaker </a> </p>
        <p>
          I did my undergraduate at <a href="http://mu.ac.in/portal/">University of Mumbai</a>, where I was advised by Prof. Rajiv Iyer. I have spent time at <a href="http://www.rri.res.in/">Raman Research Institute</a>, <a href="http://www.iitb.ac.in/">IIT Bombay</a> and <a href="https://www.here.com/en">HERE Maps</a> </p>
          <a href="mailto:pradeepsingh7890@live.com">Email</a> &nbsp/&nbsp
          <a href="JonBarron.pdf">CV</a> &nbsp/&nbsp
          <a href="JonBarron-bio.txt">Biography</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/pradeepsinngh/"> LinkedIn </a>
        </p>
        </td>
        <td width="33%">
        <img src="images/pradeep.png">
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p> My area of interest boradly lies in Computational Science with emphasis on Machine Learning, Mathematical 
		  Modeling, Data Science.</p>
		
	<p> I have previously worked on projects in the field of Signal and Image Processing. Biometrics, Computer Vision 
		and Pattern Recognition </p>
        </td>
      </tr>
      </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">


    <tr onmouseout="portrait_stop()" onmouseover="portrait_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'portrait_image'><img src='portrait_after.png'></div>
        <img src='portrait_before.png'>
        </div>
        <script type="text/javascript">
        function portrait_start() {
        document.getElementById('portrait_image').style.opacity = "1";
        }
        function portrait_stop() {
        document.getElementById('portrait_image').style.opacity = "0";
        }
        portrait_stop()
        </script>
      </td>
      <td valign="top" width="75%">
	  <a href="https://drive.google.com/file/d/13i6DlS9UhGVKmwslLUFnKBwdxFRVQeQj/view?usp=sharing">
            <project>Deep Neural Network based Speech Recognizer</project>
	  </a>
	  <br>
          <a href="http://people.csail.mit.edu/nwadhwa/">Neal Wadhwa</a>,
          <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
          <a href="http://graphics.stanford.edu/~dejacobs/">David E. Jacobs</a>,
          Bryan E. Feldman,
          Nori Kanazawa,
          Robert Carroll,
          <a href="http://www.cs.cmu.edu/~ymovshov/">Yair Movshovitz-Attias</a>,
          <strong>Jonathan T. Barron</strong>,
          Yael Pritch,
          <a href="http://graphics.stanford.edu/~levoy/">Marc Levoy</a> <br>
        <em>SIGGRAPH</em>, 2018 <br>
        <a href="https://arxiv.org/abs/1806.04171">arxiv</a>
        / 
        <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">blog post</a>
        / 
        <a href="Wadhwa2018.bib">bibtex</a>
        <p></p>
        <p>Dual pixel cameras and semantic segmentation algorithms can be used for shallow depth of field effects.</p>
        <p>This system is the basis for "Portrait Mode" on the Google Pixel 2 smartphones</p>
      </td>
    </tr>

    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'aperture_image'><img src='aperture_after.jpg'></div>
        <img src='aperture_before.jpg'>
        </div>
        <script type="text/javascript">
        function aperture_start() {
        document.getElementById('aperture_image').style.opacity = "1";
        }
        function aperture_stop() {
        document.getElementById('aperture_image').style.opacity = "0";
        }
        aperture_stop()
        </script>
      </td>
      <td valign="top" width="75%">
	  <a href="https://drive.google.com/open?id=1MpvxcW7OTJP321QL_q4ZLQ8D653bZZzy">
            <project>Machine Translation</project>
	  </a>
	  <br>
          <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul P. Srinivasan</a>,
	  <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
	  <a href="http://people.csail.mit.edu/nwadhwa/">Neal Wadhwa</a>,
	  <a href="http://graphics.stanford.edu/~renng/">Ren Ng</a>,
	  <strong>Jonathan T. Barron</strong> <br>
        <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <br>
        <a href="https://github.com/google/aperture_supervision">code</a>
        / 
        <a href="Srinivasan2018.bib">bibtex</a>
        <p></p>
        <p>Varying a camera's aperture provides a supervisory signal that can teach a neural network to do monocular depth estimation.</p>
      </td>
    </tr>
		
    <tr onmouseout="deepburst_stop()" onmouseover="deepburst_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'deepburst_image'><img src='deepburst_after.png'></div>
        <img src='deepburst_before.png'>
        </div>
        <script type="text/javascript">
        function deepburst_start() {
        document.getElementById('deepburst_image').style.opacity = "1";
        }
        function deepburst_stop() {
        document.getElementById('deepburst_image').style.opacity = "0";
        }
        deepburst_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <a href="https://drive.google.com/file/d/1GAH8ijyZ7GnoBnQFANEzdXinHrE4vvXn/view?usp=sharing">
            <project>Image Recognition using CNN based models</project>
        </a>
        <br>
        <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall</a>,
        <strong>Jonathan T. Barron</strong>,
        <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>,
        <a href="http://www.dsharlet.com/">Dillon Sharlet</a>,
        <a href="http://graphics.stanford.edu/~renng/">Ren Ng</a>,
        Robert Carroll <br>
        <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018  &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font> <br>
        <a href ="https://drive.google.com/file/d/1aqk3Q-L2spjLZh2yRWKUWIDcZkGjQ7US/view?usp=sharing">supplement</a>
        /
        <a href="Mildenhall2018.bib">bibtex</a>
        <p></p>
        <p>We train a network to predict linear kernels that denoise noisy bursts from cellphone cameras.</p>
      </td>
    </tr>
	  
    <tr onmouseout="friendly_stop()" onmouseover="friendly_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'friendly_image'><img src='friendly_after.png'></div>
        <img src='friendly_before.png'>
        </div>
        <script type="text/javascript">
        function friendly_start() {
        document.getElementById('friendly_image').style.opacity = "1";
        }
        function friendly_stop() {
        document.getElementById('friendly_image').style.opacity = "0";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://drive.google.com/file/d/1w_0djhL0QgC_fbehnJ0c-J23_kW_420p/view?usp=sharing">
            <project>Parallelizing Deep Neural Network Network using MPI and GPU Computing</project>
          <a href="https://homes.cs.washington.edu/~amrita/">Amrita Mazumdar</a>, <a href="http://homes.cs.washington.edu/~armin/">Armin Alaghi</a>, <strong>Jonathan T. Barron</strong>, <a href="https://www.cs.unc.edu/~gallup/">David Gallup</a>, <a href="https://homes.cs.washington.edu/~luisceze/">Luis Ceze</a>, <a href="https://homes.cs.washington.edu/~oskin/">Mark Oskin</a>, <a href="http://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a>  <br>
        <em>High-Performance Graphics (HPG)</em>, 2017 <br>
        <a href="https://sampa.cs.washington.edu/projects/vr-hw.html">project page</a>
        <p></p>
        <p>A reformulation of the bilateral solver can be implemented efficiently on GPUs and FPGAs.</p>
      </td>
    </tr>

    <tr onmouseout="hdrnet_stop()" onmouseover="hdrnet_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'hdrnet_image'><img src='hdrnet_after.jpg'></div>
        <img src='hdrnet_before.jpg'>
        </div>
        <script type="text/javascript">
        function hdrnet_start() {
        document.getElementById('hdrnet_image').style.opacity = "1";
        }
        function hdrnet_stop() {
        document.getElementById('hdrnet_image').style.opacity = "0";
        }
        hdrnet_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://drive.google.com/file/d/1jQY3CTMnLX7PeGUzYLso9H1eCsZyWbwg/view?usp=sharing">
            <project>Sentiment Analysis</project>
          <a href="http://www.mgharbi.com">Micha&euml;l Gharbi</a>, <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>, <strong>Jonathan T. Barron</strong>, <a href="https://people.csail.mit.edu/hasinoff/">Samuel W. Hasinoff</a>, <a href="http://people.csail.mit.edu/fredo/">Fr&eacute;do Durand </a> <br>
        <em>SIGGRAPH</em>, 2017 <br>
        <a href="https://groups.csail.mit.edu/graphics/hdrnet/">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=GAe0qKKQY_I">video</a>
        /
        <a href="GharbiSIGGRAPH2017.bib">bibtex</a>
        /
        <a href="http://news.mit.edu/2017/automatic-image-retouching-phone-0802">p</a><a href="https://www.wired.com/story/googles-new-algorithm-perfects-photos-before-you-even-take-them/">r</a><a href="https://petapixel.com/2017/08/02/new-ai-can-retouch-photos-snap/">e</a><a href="https://www.theverge.com/2017/8/2/16082272/google-mit-retouch-photos-machine-learning">s</a><a href="http://gizmodo.com/clever-camera-app-uses-deep-learning-to-perfectly-retou-1797474282">s</a>
        <p></p>
        <p>By training a deep network in bilateral space we can learn a model for high-resolution and real-time image enhancement.</p>
      </td>
    </tr>

    <tr>
      <td width="25%">
        <img src='loss.png'>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/1701.03077">
            <project>Topic Modeling - LDA</project>
          <strong>Jonathan T. Barron</strong> <br>
          <em>arXiv Preprint</em>, 2017 <br>
	  <p></p>
          <p>A single robust loss function is a superset of many other common robust loss functions.</p>
        </td>
      </tr>

    <tr onmouseout="ffcc_stop()" onmouseover="ffcc_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'ffcc_image'><img src='ffcc_after.jpg'></div>
        <img src='ffcc_before.jpg'>
        </div>
        <script type="text/javascript">
        function ffcc_start() {
        document.getElementById('ffcc_image').style.opacity = "1";
        }
        function ffcc_stop() {
        document.getElementById('ffcc_image').style.opacity = "0";
        }
        ffcc_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://drive.google.com/file/d/1VDWAS7HgiufTNPP7CQY00KmJP71QIZAy/view?usp=sharing">
            <project>Part of Speeech Tagging</project>
        <strong>Jonathan T. Barron</strong>, Yun-Ta Tsai<br>
        <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2017 <br>
        <a href ="https://drive.google.com/file/d/1b5zdR5UYPTkXa2UgiLhi-PP89bzINJSR/view?usp=sharing">supplement</a>
        /
        <a href ="https://youtu.be/rZCXSfl13rY">video</a>
        /
        <a href ="BarronTsaiCVPR2017.bib">bibtex</a>
        /
        <a href ="https://github.com/google/ffcc">code</a>
        /
        <a href="https://drive.google.com/open?id=0B4nuwEMaEsnmWkJQMlFPSFNzbEk">output</a>
        /
        <a href="https://blog.google/products/photos/six-tips-make-your-photos-pop/">blog post</a>
        /
        <a href="https://9to5google.com/2017/03/03/google-photos-auto-white-balance/">p</a><a href="https://www.engadget.com/2017/03/03/google-photos-automatically-fixes-your-pictures-white-balance/">r</a><a href="https://lifehacker.com/google-photos-will-now-automatically-adjust-the-white-b-1793009155">e</a><a href="https://petapixel.com/2017/03/06/google-photos-will-now-automatically-white-balance-snapshots/">s</a><a href="http://www.theverge.com/2017/3/3/14800062/google-photos-auto-white-balance-android">s</a>
        <p></p>
        <p>Color space can be aliased, allowing white balance models to be learned and evaluated in the frequency domain. This improves accuracy by 13-20% and speed by 250-3000x.</p>
	<p>This technology is used by <a href="https://photos.google.com/">Google Photos</a> and <a href="https://www.google.com/maps">Google Maps</a>.</p>
      </td>
    </tr>

      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="right">
          <font size="2">
          Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website"><strong>source code</strong></a>.
       	  </font>
        </p>
        </td>
      </tr>
      </table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </table>
  </body>
</html>
